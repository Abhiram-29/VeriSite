{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c1d94c-1be0-4578-b367-7a4a2e35271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BitsAndBytesConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bfd5e7-1404-49eb-8c19-c02d2f861169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_url(url):\n",
    "    url = re.sub(r'https?://', '', url)\n",
    "    parts = url.split('/', 1)\n",
    "    domain = parts[0]\n",
    "    path = parts[1] if len(parts) > 1 else \"\"\n",
    "    text_rep = f\"{domain} {path.replace('/', ' ')}\"\n",
    "\n",
    "    return text_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650631b1-f21f-481d-beab-1234e68f407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344275</td>\n",
       "      <td>http://85.217.170.105/XXX.sh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145258</td>\n",
       "      <td>technews.tmcnet.com/news/2011/07/28/5668630.htm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>391135</td>\n",
       "      <td>crownpoint.com/artists/101/biography</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>397356</td>\n",
       "      <td>mrnormsgarage.com/vehicles/1971-cuda-convertib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262630</td>\n",
       "      <td>http://www.colegiosanignacio.com.ar/index.php?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  type\n",
       "0      344275                       http://85.217.170.105/XXX.sh     0\n",
       "1      145258    technews.tmcnet.com/news/2011/07/28/5668630.htm     1\n",
       "2      391135               crownpoint.com/artists/101/biography     1\n",
       "3      397356  mrnormsgarage.com/vehicles/1971-cuda-convertib...     1\n",
       "4      262630  http://www.colegiosanignacio.com.ar/index.php?...     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./test_data.csv\")\n",
    "data['type'] = data['type'].map(lambda x: 1 if x == 'benign' else 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ae1c8f9-fc7c-4f60-a71a-7040df8b664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"deberta_v3-1\"\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",  # NormalFloat4 quantization (best for LLMs)\n",
    "        bnb_4bit_compute_dtype=torch.float16,  # Use FP16 for computation\n",
    "        bnb_4bit_use_double_quant=True,  # Further reduces memory usage\n",
    "        )\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=2,\n",
    "            quantization_config=quantization_config,  # Use the correct config format\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "model = PeftModel.from_pretrained(base_model, model_path, is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de531393-b6f8-4c58-99ef-bedc9bcdec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DebertaV2ForSequenceClassification(\n",
       "      (deberta): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): lora.Linear4bit(\n",
       "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): lora.Linear4bit(\n",
       "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (pooler): ContextPooler(\n",
       "        (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeda98c3-d229-46d2-b1f3-3acbd0b50609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [preprocess_url(url) for url in data['url']]\n",
    "y_test = [label for label in data['type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9ab08e-e756-4f13-992d-85faf1108f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataloader = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d0688ec-0df6-4f3a-a9c0-dd4ad3a74541",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_texts, batch_labels in dataloader:\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).tolist()\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f2d9419-e2b1-4fea-a514-3fa46104046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8934\n",
      "Precision: 0.8639\n",
      "Recall: 0.9347\n",
      "F1 Score: 0.8979\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.85      0.89     53104\n",
      "    Positive       0.86      0.93      0.90     53416\n",
      "\n",
      "    accuracy                           0.89    106520\n",
      "   macro avg       0.90      0.89      0.89    106520\n",
      "weighted avg       0.90      0.89      0.89    106520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average=\"binary\")\n",
    "report = classification_report(all_labels, all_predictions, target_names=[\"Negative\", \"Positive\"])\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc6e454-e59e-44f7-814d-b83fd90c9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([preprocess_url(\"https://webmail-aurba-inbox.netlify.app/\")], return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5411fa4a-32bd-497a-bcf7-e734f0d8f29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0363,  0.0664]], device='cuda:0', dtype=torch.float16), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e59d82-5bf5-43b5-8323-c09712bc1eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4744, 0.5259]], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "probs = torch.softmax(outputs.logits, dim=1)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3dca96-f346-4c79-b26a-9324f4ae076d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
